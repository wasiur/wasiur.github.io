I organise the Statistics and Probability seminars at Nottingham Maths. Below is the list of upcoming talks in the seminar series. 

## Spring 2023

<ul>
  <li>2 February 2023, 2pm. <a href="https://www.nottingham.ac.uk/mathematics/people/luis.espath">Luis Espath</a>, University of Nottingham.
    <ul>
      <li>
          <b>Title:</b> <em>  Physics-informed Spectral Learning: Wind Reconstruction</em>
      </li>
      <li>
          <b>Abstract:</b> <em>   We propose a Physics-informed Spectral Learning framework. Within this physics-informed type of statistical learning approach, we adaptively build a sparse set of Fourier basis functions with corresponding coefficients by solving a sequence of minimization problems where the set of basis functions is augmented greedily at each optimization problem. We regularize our minimization problems with the seminorm of the fractional Sobolev space in a Tikhonov fashion. To show the capability of this tool, we address two classical physical problems. First, we reconstruct the velocity field of incompressible flows given a finite set of measurements of an underlying incompressible flow. This is applied to generate the UK wind map. Second, we perform the Helmholtz--Hodge decomposition given a finite set of measurements of an underlying flow. This is used to detect the hurricane eye of the storm of the century 1993. For this spatial approximation, we developed the Sparse Fourier approximation based on a discrete $L^2$ projection. In the Fourier setting, the divergence- and curl-free constraints become a finite set of linear algebraic equations. This work is based on [1,2].
          <br>
          [1]  Luis Espath, Dmitry Kabanov, Jonas Kiessling, and RaúlTempone. Statistical learning for fluid flows: Sparse Fourier divergence-free approximations. Physics of Fluids, 33(9):097108, 2021.
          [2]  Dmitry Kabanov, Luis Espath, Jonas Kiessling, and Raúl Tempone. Estimating divergence-free flows via neural networks. PAMM, 21(1):e202100173, 2021.
          </em>
      </li>
    </ul>
  </li>
  <li>9 February 2023, 2pm. <a href="https://www.ucl.ac.uk/statistics/people/codina_cotar">Codina Cotar</a>, University College London. (Cancelled)
    <ul>
      <li>
          <b>Title:</b> <em>  TBA</em> 
      </li>
      <li>
          <b>Abstract:</b> <em>  TBA</em>
      </li>
    </ul>
  </li>
  <li>23 February 2023, 2pm. <a href="https://profiles.sussex.ac.uk/p469630-minmin-wang">Minmin Wang</a>, University of Sussex. (Cancelled)
    <ul>
      <li>
          <b>Title:</b> <em>  TBA</em>
      </li>
      <li>
          <b>Abstract:</b> <em>  TBA</em>
      </li>
    </ul>
  </li>
  <li>2 March 2023, 2pm. <a href="https://sites.google.com/view/marioberaha">Mario Beraha</a>, Università di Torino.
    <ul>
      <li>
        <b>Title:</b> <em>  Random Measure Priors in Bayesian Frequency Recovery from Sketches</em>
      </li>
      <li>
          <b>Abstract:</b> <em>  Consider the problem of dealing with a stream of tokens, where each token could be an IP address, a URL, or a language n-gram. Each token takes values in a set whose dimension is too large to store in a computer, and a compression strategy must be devised for inference. The count-min sketch (CMS) is a randomized data structure dealing with situations as before. In a CMS, data is processed by multiple random hash functions that map the tokens’ space into {1, …, J}. Since J is smaller than the total number of possible tokens, applying the hash function leads to a loss in the information stored. Nonetheless, it is possible to estimate the frequency of each token (i.e., how many times it appeared) with high accuracy, at least in probability, even for moderate values of J and hash functions.
          In the traditional CMS, the stream of tokens is treated as a deterministic sequence, and randomness is introduced by considering i.i.d. random hash functions. Here, we take a statistical point of view and propose to consider a probabilistic model for the data as well, specifically a Bayesian nonparametric species sampling model. We provide an explicit expression for the posterior probability of the frequency of each token for a wide class of priors, namely the Poisson-Kingman class. However, we show that the Dirichlet process is the only prior leading to a tractable expression.  Then, we generalize our approach to more complex data streams, considering, for instance, streams of documents made of several n-grams. 
          Joint work with Stefano Favaro 
          </em>
      </li>
    </ul>
  </li>
  <li>8 March 2023, 2pm. <a href="https://sites.google.com/view/sp-monte-carlo">Sam Power</a>, University of Bristol.
    <ul>
      <li>
        <b>Title:</b> <em>  Explicit convergence bounds for Metropolis Markov chains</em>
      </li>
      <li>
          <b>Abstract:</b> <em>  Markov chain Monte Carlo (MCMC) algorithms are a widely-used tool for approximate simulation from probability measures in structured, high-dimensional spaces, with a variety of applications. A key ingredient of their success is their ability to converge rapidly to equilibrium at a rate which depends acceptably on the ‘difficulty' of the sampling problem at hand, as captured by the dimension of the problem, and the curvature and concentration properties of the target distribution.
          <br>
          In this talk, I will present recent work with C. Andrieu, A. Lee and A. Wang on the convergence analysis of Metropolis-type MCMC algorithms on R^d. In particular, we provide a detailed study of the Random Walk Metropolis (RWM) Markov chain with arbitrary proposal variances and in any dimension, obtaining interpretable estimates on their convergence behaviour under suitable assumptions. These estimates have a provably sharp dependence on the dimension of the problem, thus providing theoretical validation for the use of these algorithms in complex settings.
          <br>
          Our positive results are quite generally applicable. We also study the preconditioned Crank--Nicolson Markov chain as applied to simulation from Gaussian Process posterior models, obtaining dimension-independent complexity bounds under suitable assumptions.
          <br>
          Preprint available at <https://arxiv.org/abs/2211.08959>.
          </em>
      </li>
    </ul>
  </li>
  <li>23 March 2023, 2pm. <a href="https://www.nottingham.ac.uk/mathematics/people/olga.iziumtseva">Olga Iziumtseva</a>, University of Nottingham.
    <ul>
      <li>
         <b>Title:</b> <em>  TBA</em> 
      </li>
      <li>
          <b>Abstract:</b> <em>  TBA</em>
      </li>
    </ul>
  </li>
  <li>6 April 2023, 2pm. <a href="https://fadikar.com/about/">Arindam Fadikar</a>, Argonne National Laboratory.
    <ul>
      <li> <b>Title:</b> <em>  TBA</em></li>
      <li>
        <b>Abstract:</b> 
           <em>  TBA</em>
      </li>
    </ul>
  </li>
  <li>20 April 2023, 2pm. <a href="https://www.nottingham.ac.uk/mathematics/people/federico.girotti">Federico Girotti</a>, University of Nottingham.
    <ul>
      <li> <b>Title:</b> <em>  TBA</em></li>
      <li>
        <b>Abstract:</b> 
           <em>  TBA</em>
      </li>
    </ul>
  </li>
  <li>27 April 2023, 2pm. <a href="https://mzhilova7.math.gatech.edu/">Mayya Zhilova</a>, Georgia Tech.
    <ul>
      <li> <b>Title:</b> <em>  TBA</em></li>
      <li>
        <b>Abstract:</b>
           <em>  TBA</em>
      </li>
    </ul>
  </li>
</ul>

## Autumn 2023
<ul>
  <li>19 October 2023, 2pm. <a href="https://www.lshtm.ac.uk/aboutus/people/keogh.ruth">Ruth Keogh</a>, London School of Hygiene and Tropical Medicine.
    <ul>
      <li>
          <b>Title:</b> <em>  TBA</em>
      </li>
      <li>
        <b>Abstract:</b> <em>  TBA
        </em>
      </li>
    </ul>
  </li>
</ul>


You can find past seminars here: [Autumn 2022](https://www.wasiur.xyz/UoNMaths_SP_Seminars/AU2022.html)
